{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import urllib\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import html5lib\n",
    "from selenium import *\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 카테고리에서 URL 받아오기\n",
    "def get_URL():\n",
    "    URL_list=[]\n",
    "    for page in range(1,10):\n",
    "        URL ='https://pc.video.dmkt-sp.jp/genre/genre-list/id/' + str(100+page)       \n",
    "        URL_list.append(URL)\n",
    "    return URL_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '각 드라마 모두보기'에서 드라마 클릭하기\n",
    "def drama_click():\n",
    "    allFind = driver.find_element_by_css_selector('h2 > span > a > span')\n",
    "    allFind.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#스크롤 내리기\n",
    "def page_down_drama():\n",
    "    body=driver.find_element_by_tag_name('body')\n",
    "    num_pagedown = 100\n",
    "    while num_pagedown:\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(0.3)\n",
    "        num_pagedown-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# href 받아오기\n",
    "def get_href():\n",
    "    source = driver.page_source\n",
    "    soup = BeautifulSoup(source,'html.parser')\n",
    "    hrefs = soup.select(\"a[class=titleCard_link]\")\n",
    "\n",
    "    hrefs_lists=[]\n",
    "    for hre in hrefs:\n",
    "        h = hre.get('href')\n",
    "        hrefs_lists.append(h)\n",
    "    return hrefs_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#작품 정보, 제목,에피소드,키워드 추출(완)\n",
    "drama = []\n",
    "def get_info():\n",
    "    global title, episode\n",
    "\n",
    "    try:\n",
    "        detail_list=[]\n",
    "        find_detail = soup.findAll(\"p\",{\"class\" : \"titleDetailInfo_tx titleDetailInfo_tx--wide\"})\n",
    "        for details in find_detail:\n",
    "            detail_list.append(details.text)\n",
    "            if len(detail_list) < 1:\n",
    "                detail_list=None\n",
    "    except:\n",
    "        detail_list=[]\n",
    "\n",
    "    try:\n",
    "        find_title = soup.findAll(\"span\",{\"class\" : \"titleDetailHeading_title\"})\n",
    "        for title in find_title:\n",
    "            title=title.text\n",
    "    except:\n",
    "        title = None\n",
    "\n",
    "    try :\n",
    "        episode = \"\"\n",
    "        find_ep = soup.findAll(\"p\",{\"class\" : \"titleDetailChapter_title\"})\n",
    "        for episodes in find_ep:\n",
    "            episode.append(episodes.text)\n",
    "            if len(episode) < 1:\n",
    "                episode = None\n",
    "    except :\n",
    "        episode = None\n",
    "\n",
    "    try:\n",
    "        keyword=[]\n",
    "        find_kwd = soup.findAll(\"span\", {\"class\" : \"titleDetailKeyword_string\"})\n",
    "        for keywd in find_kwd:\n",
    "            keyword.append(keywd.text)\n",
    "    except:\n",
    "        keyword=[]\n",
    "        \n",
    "    try:\n",
    "        category = driver.find_element_by_css_selector('h1 > ul > li:nth-child(2) > a').text\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "    drama.append({'category':category,\n",
    "                'title':title,\n",
    "                'detail':detail_list,\n",
    "                 'episode':episode,\n",
    "                 'keyword':keyword})\n",
    "\n",
    "    return drama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 창 열기\n",
    "driver = webdriver.Chrome('./chromedriver.exe')\n",
    "driver.implicitly_wait(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\py373\\lib\\site-packages\\ipykernel_launcher.py:20: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dd99f95ae242f38c325b35f92f73fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index의 값을 가져올 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tnrange\n",
    "\n",
    "# 카테고리 별 정보 갖고 오기\n",
    "\n",
    "cat_drama_dict = {}\n",
    "url = get_URL()[7]\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    drama_click()\n",
    "\n",
    "    current_URL= driver.current_url\n",
    "    resource = requests.get(current_URL)\n",
    "    source = driver.page_source\n",
    "    soup = BeautifulSoup(source,'html.parser')\n",
    "\n",
    "    page_down_drama()\n",
    "\n",
    "    # 갖고 올 모든 정보 출력\n",
    "    for u in tnrange(5000):\n",
    "        try:\n",
    "            g = get_href()[u]\n",
    "            req = requests.get(g)\n",
    "            source = req.text\n",
    "            soup = BeautifulSoup(source, 'html.parser')\n",
    "            info_df = pd.DataFrame(get_info())\n",
    "            time.sleep(0.1)\n",
    "\n",
    "        except IndexError:\n",
    "            print('index의 값을 가져올 수 없습니다.')\n",
    "            break\n",
    "\n",
    "\n",
    "    # 데이터의 중복 제거        \n",
    "    info_df.drop_duplicates('title',keep='first')\n",
    "\n",
    "except NoSuchElementException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import tnrange\n",
    "\n",
    "# # 카테고리 별 정보 갖고 오기\n",
    "# for i in range(10):\n",
    "#     cat_drama_dict = {}\n",
    "#     url = get_URL()[i]\n",
    "#     driver.get(url)\n",
    "    \n",
    "#     try:\n",
    "#         drama_click()\n",
    "        \n",
    "#         current_URL= driver.current_url\n",
    "#         resource = requests.get(current_URL)\n",
    "#         source = driver.page_source\n",
    "#         soup = BeautifulSoup(source,'html.parser')\n",
    "        \n",
    "#         page_down_drama()\n",
    "\n",
    "#         # 갖고 올 모든 정보 출력\n",
    "#         for u in tnrange(5000):\n",
    "#             try:\n",
    "#                 g = get_href()[u]\n",
    "#                 req = requests.get(g)\n",
    "#                 source = req.text\n",
    "#                 soup = BeautifulSoup(source, 'html.parser')\n",
    "#                 info_df = pd.DataFrame(get_info())\n",
    "#                 time.sleep(0.1)\n",
    "                \n",
    "#             except IndexError:\n",
    "#                 pass\n",
    "#                 print('index의 값을 가져올 수 없습니다.')\n",
    "            \n",
    "#         # 데이터의 중복 제거        \n",
    "#         info_df.drop_duplicates('title',keep='first')\n",
    "              \n",
    "#     except NoSuchElementException:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 엑셀에 저장하기\n",
    "\n",
    "fin_table = pd.DataFrame(info_df)\n",
    "fin_table.to_excel(\"test8.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
